import { Message } from '../types/message';\nimport { MessageCache } from './MessageCache';\nimport { MessagingPerformanceOptimizer, OptimizationConfig } from './messagingPerformanceOptimizer';\nimport { ApiResponse } from '../types/messaging';\n\nexport interface PerformanceTestConfig {\n  /**\n   * Number of test messages to generate\n   */\n  messageCount: number;\n  \n  /**\n   * Number of test conversations\n   */\n  conversationCount: number;\n  \n  /**\n   * Number of concurrent operations to test\n   */\n  concurrency: number;\n  \n  /**\n   * Test duration in milliseconds\n   */\n  duration: number;\n  \n  /**\n   * Whether to test cache performance\n   */\n  testCache: boolean;\n  \n  /**\n   * Whether to test optimistic updates\n   */\n  testOptimistic: boolean;\n  \n  /**\n   * Whether to test API batching\n   */\n  testBatching: boolean;\n  \n  /**\n   * Simulated network delay in milliseconds\n   */\n  networkDelay: number;\n  \n  /**\n   * Simulated error rate (0-1)\n   */\n  errorRate: number;\n}\n\nexport interface PerformanceTestResult {\n  /**\n   * Test configuration used\n   */\n  config: PerformanceTestConfig;\n  \n  /**\n   * Test duration in milliseconds\n   */\n  duration: number;\n  \n  /**\n   * Cache performance results\n   */\n  cacheResults?: {\n    hitRate: number;\n    averageHitTime: number;\n    averageMissTime: number;\n    totalOperations: number;\n  };\n  \n  /**\n   * Optimistic update results\n   */\n  optimisticResults?: {\n    successRate: number;\n    averageConfirmTime: number;\n    totalUpdates: number;\n    failedUpdates: number;\n  };\n  \n  /**\n   * API batching results\n   */\n  batchingResults?: {\n    batchEfficiency: number;\n    averageBatchSize: number;\n    totalBatches: number;\n    totalRequests: number;\n  };\n  \n  /**\n   * Memory usage results\n   */\n  memoryResults: {\n    initialMemory: number;\n    peakMemory: number;\n    finalMemory: number;\n    memoryGrowth: number;\n  };\n  \n  /**\n   * Overall performance score (0-100)\n   */\n  performanceScore: number;\n  \n  /**\n   * Performance recommendations\n   */\n  recommendations: string[];\n  \n  /**\n   * Detailed timing data\n   */\n  timingData: {\n    operation: string;\n    duration: number;\n    timestamp: number;\n  }[];\n}\n\nexport class MessagingPerformanceTester {\n  private messageCache: MessageCache;\n  private optimizer: MessagingPerformanceOptimizer;\n  private testMessages: Message[] = [];\n  private testConversationIds: string[] = [];\n  private timingData: { operation: string; duration: number; timestamp: number; }[] = [];\n  \n  constructor(\n    messageCache?: MessageCache,\n    optimizerConfig?: Partial<OptimizationConfig>\n  ) {\n    this.messageCache = messageCache || new MessageCache();\n    this.optimizer = new MessagingPerformanceOptimizer(this.messageCache, optimizerConfig);\n  }\n  \n  /**\n   * Run comprehensive performance tests\n   */\n  async runPerformanceTests(config: Partial<PerformanceTestConfig> = {}): Promise<PerformanceTestResult> {\n    const testConfig: PerformanceTestConfig = {\n      messageCount: 1000,\n      conversationCount: 10,\n      concurrency: 5,\n      duration: 30000, // 30 seconds\n      testCache: true,\n      testOptimistic: true,\n      testBatching: true,\n      networkDelay: 100,\n      errorRate: 0.05,\n      ...config\n    };\n    \n    console.log('Starting performance tests with config:', testConfig);\n    \n    const startTime = Date.now();\n    const initialMemory = this.estimateMemoryUsage();\n    \n    // Generate test data\n    await this.generateTestData(testConfig);\n    \n    const results: Partial<PerformanceTestResult> = {\n      config: testConfig,\n      timingData: [],\n      memoryResults: {\n        initialMemory,\n        peakMemory: initialMemory,\n        finalMemory: 0,\n        memoryGrowth: 0\n      }\n    };\n    \n    // Run cache performance tests\n    if (testConfig.testCache) {\n      results.cacheResults = await this.testCachePerformance(testConfig);\n    }\n    \n    // Run optimistic update tests\n    if (testConfig.testOptimistic) {\n      results.optimisticResults = await this.testOptimisticUpdates(testConfig);\n    }\n    \n    // Run batching tests\n    if (testConfig.testBatching) {\n      results.batchingResults = await this.testApiBatching(testConfig);\n    }\n    \n    // Calculate final memory usage\n    const finalMemory = this.estimateMemoryUsage();\n    results.memoryResults!.finalMemory = finalMemory;\n    results.memoryResults!.memoryGrowth = finalMemory - initialMemory;\n    \n    // Calculate performance score and recommendations\n    const duration = Date.now() - startTime;\n    results.duration = duration;\n    results.timingData = this.timingData;\n    results.performanceScore = this.calculatePerformanceScore(results as PerformanceTestResult);\n    results.recommendations = this.generateRecommendations(results as PerformanceTestResult);\n    \n    console.log('Performance tests completed in', duration, 'ms');\n    \n    return results as PerformanceTestResult;\n  }\n  \n  /**\n   * Test cache performance\n   */\n  private async testCachePerformance(config: PerformanceTestConfig): Promise<{\n    hitRate: number;\n    averageHitTime: number;\n    averageMissTime: number;\n    totalOperations: number;\n  }> {\n    console.log('Testing cache performance...');\n    \n    let hits = 0;\n    let misses = 0;\n    let hitTimes: number[] = [];\n    let missTimes: number[] = [];\n    \n    const operations = config.messageCount;\n    \n    for (let i = 0; i < operations; i++) {\n      const conversationId = this.testConversationIds[i % this.testConversationIds.length];\n      const startTime = Date.now();\n      \n      const cachedMessages = this.messageCache.get(conversationId);\n      const duration = Date.now() - startTime;\n      \n      if (cachedMessages) {\n        hits++;\n        hitTimes.push(duration);\n      } else {\n        misses++;\n        missTimes.push(duration);\n        \n        // Simulate loading and caching\n        const messages = this.testMessages.filter(m => m.conversationId === conversationId);\n        this.messageCache.set(conversationId, messages);\n      }\n      \n      this.recordTiming('cache-operation', duration);\n    }\n    \n    return {\n      hitRate: hits / (hits + misses),\n      averageHitTime: hitTimes.length > 0 ? hitTimes.reduce((sum, t) => sum + t, 0) / hitTimes.length : 0,\n      averageMissTime: missTimes.length > 0 ? missTimes.reduce((sum, t) => sum + t, 0) / missTimes.length : 0,\n      totalOperations: operations\n    };\n  }\n  \n  /**\n   * Test optimistic updates\n   */\n  private async testOptimisticUpdates(config: PerformanceTestConfig): Promise<{\n    successRate: number;\n    averageConfirmTime: number;\n    totalUpdates: number;\n    failedUpdates: number;\n  }> {\n    console.log('Testing optimistic updates...');\n    \n    let successCount = 0;\n    let failedCount = 0;\n    let confirmTimes: number[] = [];\n    \n    const updates = Math.min(config.messageCount / 10, 100); // Limit optimistic tests\n    \n    for (let i = 0; i < updates; i++) {\n      const conversationId = this.testConversationIds[i % this.testConversationIds.length];\n      const message = this.createTestMessage(conversationId, `Optimistic test ${i}`);\n      \n      try {\n        const startTime = Date.now();\n        \n        await this.optimizer.sendMessageOptimistic(\n          message,\n          this.createMockApiCall(config.networkDelay, config.errorRate)\n        );\n        \n        const confirmTime = Date.now() - startTime;\n        confirmTimes.push(confirmTime);\n        successCount++;\n        \n        this.recordTiming('optimistic-success', confirmTime);\n      } catch (error) {\n        failedCount++;\n        this.recordTiming('optimistic-failure', Date.now() - Date.now());\n      }\n    }\n    \n    return {\n      successRate: successCount / (successCount + failedCount),\n      averageConfirmTime: confirmTimes.length > 0 ? confirmTimes.reduce((sum, t) => sum + t, 0) / confirmTimes.length : 0,\n      totalUpdates: updates,\n      failedUpdates: failedCount\n    };\n  }\n  \n  /**\n   * Test API batching\n   */\n  private async testApiBatching(config: PerformanceTestConfig): Promise<{\n    batchEfficiency: number;\n    averageBatchSize: number;\n    totalBatches: number;\n    totalRequests: number;\n  }> {\n    console.log('Testing API batching...');\n    \n    // This is a simplified test - in reality, batching would be more complex\n    const requests = config.messageCount / 10;\n    const expectedBatches = Math.ceil(requests / 5); // Assuming batch size of 5\n    \n    let actualBatches = 0;\n    let totalRequests = 0;\n    \n    // Simulate batched requests\n    for (let i = 0; i < requests; i += 5) {\n      const batchSize = Math.min(5, requests - i);\n      actualBatches++;\n      totalRequests += batchSize;\n      \n      // Simulate batch processing time\n      await this.delay(config.networkDelay);\n      this.recordTiming('batch-request', config.networkDelay);\n    }\n    \n    return {\n      batchEfficiency: expectedBatches / actualBatches,\n      averageBatchSize: totalRequests / actualBatches,\n      totalBatches: actualBatches,\n      totalRequests\n    };\n  }\n  \n  /**\n   * Generate test data\n   */\n  private async generateTestData(config: PerformanceTestConfig): Promise<void> {\n    console.log('Generating test data...');\n    \n    // Generate conversation IDs\n    this.testConversationIds = [];\n    for (let i = 0; i < config.conversationCount; i++) {\n      this.testConversationIds.push(`test-conversation-${i}`);\n    }\n    \n    // Generate test messages\n    this.testMessages = [];\n    for (let i = 0; i < config.messageCount; i++) {\n      const conversationId = this.testConversationIds[i % config.conversationCount];\n      const message = this.createTestMessage(conversationId, `Test message ${i}`);\n      this.testMessages.push(message);\n    }\n    \n    console.log(`Generated ${this.testMessages.length} messages across ${this.testConversationIds.length} conversations`);\n  }\n  \n  /**\n   * Create a test message\n   */\n  private createTestMessage(conversationId: string, text: string): Message {\n    return {\n      _id: `test-message-${Date.now()}-${Math.random()}`,\n      conversationId,\n      fromUserId: 'test-user-1',\n      toUserId: 'test-user-2',\n      text,\n      type: 'text',\n      createdAt: Date.now(),\n      status: 'sent'\n    };\n  }\n  \n  /**\n   * Create mock API call for testing\n   */\n  private createMockApiCall(delay: number, errorRate: number) {\n    return async (messageData: any): Promise<ApiResponse<Message>> => {\n      await this.delay(delay);\n      \n      if (Math.random() < errorRate) {\n        return {\n          success: false,\n          error: {\n            code: 'TEST_ERROR',\n            message: 'Simulated API error'\n          }\n        };\n      }\n      \n      return {\n        success: true,\n        data: {\n          ...messageData,\n          _id: `api-message-${Date.now()}-${Math.random()}`,\n          createdAt: Date.now()\n        }\n      };\n    };\n  }\n  \n  /**\n   * Calculate overall performance score\n   */\n  private calculatePerformanceScore(results: PerformanceTestResult): number {\n    let score = 100;\n    \n    // Cache performance (30% weight)\n    if (results.cacheResults) {\n      const cacheScore = results.cacheResults.hitRate * 30;\n      score = score - 30 + cacheScore;\n    }\n    \n    // Optimistic updates (25% weight)\n    if (results.optimisticResults) {\n      const optimisticScore = results.optimisticResults.successRate * 25;\n      score = score - 25 + optimisticScore;\n    }\n    \n    // Memory efficiency (20% weight)\n    const memoryGrowthPenalty = Math.min(20, (results.memoryResults.memoryGrowth / (1024 * 1024)) * 2); // 2 points per MB\n    score -= memoryGrowthPenalty;\n    \n    // Response time (25% weight)\n    const avgResponseTime = results.timingData.reduce((sum, t) => sum + t.duration, 0) / results.timingData.length;\n    const responseScore = Math.max(0, 25 - (avgResponseTime / 100)); // Penalty for slow responses\n    score = score - 25 + responseScore;\n    \n    return Math.max(0, Math.min(100, score));\n  }\n  \n  /**\n   * Generate performance recommendations\n   */\n  private generateRecommendations(results: PerformanceTestResult): string[] {\n    const recommendations: string[] = [];\n    \n    if (results.cacheResults && results.cacheResults.hitRate < 0.7) {\n      recommendations.push('Consider increasing cache size or TTL to improve hit rate');\n    }\n    \n    if (results.optimisticResults && results.optimisticResults.successRate < 0.9) {\n      recommendations.push('High optimistic update failure rate - check network stability');\n    }\n    \n    if (results.memoryResults.memoryGrowth > 10 * 1024 * 1024) { // 10MB\n      recommendations.push('High memory growth detected - consider implementing memory cleanup');\n    }\n    \n    const avgResponseTime = results.timingData.reduce((sum, t) => sum + t.duration, 0) / results.timingData.length;\n    if (avgResponseTime > 1000) {\n      recommendations.push('Average response time is high - consider optimizing API calls');\n    }\n    \n    if (results.performanceScore < 70) {\n      recommendations.push('Overall performance is below optimal - review all optimization strategies');\n    }\n    \n    return recommendations;\n  }\n  \n  /**\n   * Record timing data\n   */\n  private recordTiming(operation: string, duration: number): void {\n    this.timingData.push({\n      operation,\n      duration,\n      timestamp: Date.now()\n    });\n  }\n  \n  /**\n   * Estimate memory usage\n   */\n  private estimateMemoryUsage(): number {\n    // Rough estimate based on cached data\n    const stats = this.messageCache.getStats();\n    return stats.totalMessages * 1024; // 1KB per message estimate\n  }\n  \n  /**\n   * Utility delay function\n   */\n  private delay(ms: number): Promise<void> {\n    return new Promise(resolve => setTimeout(resolve, ms));\n  }\n  \n  /**\n   * Clean up test data and resources\n   */\n  destroy(): void {\n    this.messageCache.clear();\n    this.optimizer.destroy();\n    this.testMessages = [];\n    this.testConversationIds = [];\n    this.timingData = [];\n  }\n}\n\n/**\n * Run quick performance benchmark\n */\nexport async function runQuickPerformanceBenchmark(): Promise<PerformanceTestResult> {\n  const tester = new MessagingPerformanceTester();\n  \n  try {\n    const results = await tester.runPerformanceTests({\n      messageCount: 100,\n      conversationCount: 5,\n      duration: 5000, // 5 seconds\n      networkDelay: 50,\n      errorRate: 0.02\n    });\n    \n    console.log('Quick benchmark results:', {\n      score: results.performanceScore,\n      cacheHitRate: results.cacheResults?.hitRate,\n      optimisticSuccessRate: results.optimisticResults?.successRate,\n      memoryGrowth: results.memoryResults.memoryGrowth\n    });\n    \n    return results;\n  } finally {\n    tester.destroy();\n  }\n}\n\n/**\n * Run comprehensive performance test suite\n */\nexport async function runComprehensivePerformanceTests(): Promise<PerformanceTestResult> {\n  const tester = new MessagingPerformanceTester();\n  \n  try {\n    const results = await tester.runPerformanceTests({\n      messageCount: 1000,\n      conversationCount: 20,\n      duration: 30000, // 30 seconds\n      networkDelay: 100,\n      errorRate: 0.05\n    });\n    \n    console.log('Comprehensive test results:', {\n      score: results.performanceScore,\n      recommendations: results.recommendations\n    });\n    \n    return results;\n  } finally {\n    tester.destroy();\n  }\n}"